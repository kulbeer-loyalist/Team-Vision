{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility of the results\n",
    "\n",
    "Setting the random seed for the random number generators used in the code, to ensure that the random processes, likd data shuffling or weight initialization, produce the same results every time we run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the landmarks\n",
    "- Set up the paths of folders to locate the landmarks and the list (csv file) that associates the name of the video to the corresponding word in English.\n",
    "- Creation of a dictionary to associate the words to a unique number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up of the extracted landmarks save path\n",
    "landmarks_path = 'C:/Users/marcu/OneDrive/Documentos/Loyalist_College/AISC2006/predictions_wlasl_for_gd/landmarks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the file dataset_analysis.csv to load the association of landmark ids to words and its number of frames\n",
    "file, word = [], []\n",
    "\n",
    "with open(landmarks_path + \"Updated Dataset_dog_happy_jump.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)  # reading the data\n",
    "    next(csv_reader)  # to skip the header\n",
    "    for row in csv_reader:\n",
    "        file.append(landmarks_path + str(row[0]) + '.parquet')  # getting the files to load\n",
    "        word.append(row[1])  # getting the words corresponding to the files to load\n",
    "\n",
    "# sign_dict = {}  # initializing the dictionary that will receive the data\n",
    "# for idx, row in enumerate(np.unique(word)):\n",
    "#     sign_dict[row] = idx  # storing the content into a dictionary\n",
    "\n",
    "file = np.array(file)\n",
    "word = np.array(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the json file adn creation of dictionary to associate the words to a unique number\n",
    "with open('sign_to_prediction_index_map.json', 'r') as j:\n",
    "     sign_dict = json.loads(j.read())\n",
    "\n",
    "del j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and shaping the landmarks to the desired number of frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desired number of frames\n",
    "- Each video will be reshaped to have the number of rows (or frames) equal to the desired number of frames defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Landmark points to keep\n",
    "- The objective is to reduce the number of features.\n",
    "- All the landmarks from the hands will be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_keep_points = [0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 61, 185, 40, 39, 37]\n",
    "face_keep_points.sort()\n",
    "left_hand_keep_points = [i for i in range(21)]\n",
    "pose_keep_points = [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "right_hand_keep_points = [i for i in range(21)]\n",
    "\n",
    "face_keep_idx = [face_keep_points[i] for i in range(len(face_keep_points))]\n",
    "left_hand_keep_idx = [i + 468 for i in left_hand_keep_points]\n",
    "pose_keep_idx = [i + 468 + 21 for i in pose_keep_points]\n",
    "right_hand_keep_idx = [i + 468 + 21 + 33 for i in right_hand_keep_points]\n",
    "\n",
    "landmarks_to_keep = face_keep_idx + left_hand_keep_idx + pose_keep_idx + right_hand_keep_idx\n",
    "\n",
    "del face_keep_points, left_hand_keep_points, pose_keep_points, right_hand_keep_points\n",
    "del face_keep_idx, left_hand_keep_idx, pose_keep_idx, right_hand_keep_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_ROWS = 543\n",
    "desired_num_rows = len(landmarks_to_keep) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading all the landmarks\n",
    "- The 'z' coordinate will be dropped because, according to Google, it “should be discarded as currently the model is not fully trained to predict depth”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 33.21it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_landmarks():\n",
    "\n",
    "    # Columns to upload\n",
    "    data_columns = ['x', 'y']\n",
    "\n",
    "    landmarks = np.empty((file.shape[0], NUM_FRAMES, desired_num_rows), dtype=float)\n",
    "    labels = []\n",
    "    \n",
    "    for i in tqdm(range(file.shape[0])):\n",
    "\n",
    "        # Loading the file\n",
    "        data = pd.read_parquet(file[i], columns=data_columns).fillna(0)\n",
    "        num_frames = int(len(data) / TOTAL_ROWS)\n",
    "        data = data.values.reshape(num_frames, TOTAL_ROWS, len(data_columns))\n",
    "        data.astype(np.float32)\n",
    "\n",
    "        # Dropping undesired points\n",
    "        data = data[:, landmarks_to_keep]\n",
    "\n",
    "        # Adjusting the number of frames\n",
    "        if data.shape[0] > NUM_FRAMES:  # time-based sampling\n",
    "            indices = np.arange(0, data.shape[0], data.shape[0] // NUM_FRAMES)[:NUM_FRAMES]\n",
    "            data = data[indices]\n",
    "        elif data.shape[0] < NUM_FRAMES:  # padding the videos\n",
    "            rows = NUM_FRAMES - data.shape[0]\n",
    "            data = np.append(np.zeros((rows, len(landmarks_to_keep), len(data_columns))), data, axis=0)\n",
    "\n",
    "        # Reshaping the data\n",
    "        landmarks[i] = data.reshape(NUM_FRAMES, len(landmarks_to_keep) * len(data_columns), order='F')\n",
    "        del data\n",
    "\n",
    "        # Creating the labels dataset\n",
    "        labels.append(sign_dict[word[i]])\n",
    "    return landmarks, np.array(labels)\n",
    "\n",
    "x_test, y_test = load_landmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the x datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalizing the data\n",
    "# def normalize(array):\n",
    "#     return (array - np.min(array)) / (np.max(array) - np.min(array))\n",
    "# x_test = normalize(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding the y datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# label_binarizer = LabelBinarizer()\n",
    "# y_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "# del label_binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = np.zeros((x_test.shape[0], 250))\n",
    "for i in range(len(y_encoded)):\n",
    "    y_encoded[i, y_test[i]] = 1\n",
    "\n",
    "y_test = y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.callbacks import TensorBoard\n",
    "# import keras_tuner as kt\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 158)]       0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 256)         40704     \n",
      "                                                                 \n",
      " layer_normalization (LayerN  (None, None, 256)        512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, 256)         0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 256)         0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 128)         32896     \n",
      "                                                                 \n",
      " layer_normalization_1 (Laye  (None, None, 128)        256       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, 128)         0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 256)         33024     \n",
      "                                                                 \n",
      " layer_normalization_2 (Laye  (None, None, 256)        512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, 256)         0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 256)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               525312    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 250)               64250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 697,466\n",
      "Trainable params: 697,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LayerNormalization, Activation, Dropout, LSTM, Input\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Dense(256)(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(128)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(256)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    lstm_output = LSTM(256)(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation='softmax')(lstm_output)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Assuming input_shape is (None, 246) and num_classes is 250\n",
    "input_shape = (None, 158)\n",
    "num_classes = 250\n",
    "model = build_model(input_shape, num_classes)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('07-25_ARM_GD_baseline.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 12:09:58.204941: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 415ms/step\n",
      "Predicted words:\n",
      "['sticky' 'drawer' 'vacuum' 'red' 'cheek' 'red' 'zipper' 'beside'\n",
      " 'hesheit' 'black' 'giraffe' 'thirsty' 'hungry' 'hungry' 'shhh' 'black'\n",
      " 'zipper' 'puppy' 'dog' 'shhh' 'beside' 'black']\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "predicted_labels = model.predict(x_test)\n",
    "\n",
    "# Getting the predicted labels and words\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)\n",
    "predicted_words = np.array([list(sign_dict.keys())[list(sign_dict.values()).index(label)] for label in predicted_labels])\n",
    "\n",
    "# Printing the predicted words\n",
    "print('Predicted words:')\n",
    "print(predicted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy score\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), predicted_labels)\n",
    "\n",
    "# Printing the accuracy score\n",
    "print(\"Test Dataset Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
