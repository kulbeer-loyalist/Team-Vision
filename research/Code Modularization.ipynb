{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4eafe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\saran\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\saran\\anaconda3\\lib\\site-packages (from mediapipe) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\saran\\anaconda3\\lib\\site-packages (from mediapipe) (3.5.2)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\saran\\anaconda3\\lib\\site-packages (from mediapipe) (4.8.0.74)\n",
      "Requirement already satisfied: absl-py in c:\\users\\saran\\anaconda3\\lib\\site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\saran\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009a5fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\saran\\anaconda3\\lib\\site-packages (12.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from pyarrow) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d692765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55bda74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic.Holistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3eebc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "videos_path = \"C:\\\\Users\\\\saran\\\\OneDrive\\\\Desktop\\\\video_dummy_data\\\\\"\n",
    "output_path = \"C:\\\\Users\\\\saran\\\\OneDrive\\\\Desktop\\\\extracted_landmarks_dummy\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a62dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor:\n",
    "    def __init__(self, videos_path, output_path):\n",
    "        self.videos_path = videos_path\n",
    "        self.output_path = output_path\n",
    "        self.mp_holistic = mp.solutions.holistic.Holistic(static_image_mode=False)\n",
    "\n",
    "    def process_videos(self):\n",
    "        # Create a list to store the video analysis results\n",
    "        video_results = []\n",
    "\n",
    "        # Iterate over the videos in the videos_path\n",
    "        for filename in os.listdir(self.videos_path):\n",
    "            if filename.endswith(\".mp4\"):\n",
    "                video_path = os.path.join(self.videos_path, filename)\n",
    "                video_name = os.path.splitext(filename)[0]\n",
    "                 \n",
    "                    # Open the video\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "                # Process each frame in the video\n",
    "                while cap.isOpened():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                       \n",
    "                    # Perform holistic analysis using Mediapipe\n",
    "                    with self.mp_holistic as holistic:\n",
    "                        results = holistic.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                    \n",
    "                    if results is not None:\n",
    "                            video_results.append((video_name, results))\n",
    "                    else:\n",
    "                            video_results.append((video_name, None))\n",
    "\n",
    "                    # Store the analysis results in a list\n",
    "                    video_results.append((video_name, results))\n",
    "\n",
    "                    # Visualize the results on the frame\n",
    "                    if results.pose_landmarks:\n",
    "                        mp.solutions.drawing_utils.draw_landmarks(\n",
    "                            frame,\n",
    "                            results.pose_landmarks,\n",
    "                            mp.solutions.holistic.POSE_CONNECTIONS\n",
    "                        )\n",
    "                    if results.left_hand_landmarks:\n",
    "                        mp.solutions.drawing_utils.draw_landmarks(\n",
    "                            frame,\n",
    "                            results.left_hand_landmarks,\n",
    "                            mp.solutions.holistic.HAND_CONNECTIONS\n",
    "                        )\n",
    "                    if results.right_hand_landmarks:\n",
    "                        mp.solutions.drawing_utils.draw_landmarks(\n",
    "                            frame,\n",
    "                            results.right_hand_landmarks,\n",
    "                            mp.solutions.holistic.HAND_CONNECTIONS\n",
    "                        )\n",
    "\n",
    "                    # Display the frame with landmarks\n",
    "                    cv2.imshow('Frame', frame)\n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "\n",
    "                # Release the video capture object\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "        # Save the video analysis results to a Parquet file\n",
    "        video_data = pa.Table.from_pandas(pd.DataFrame(video_results, columns=[\"Video\", \"Results\"]))\n",
    "        pq.write_table(video_data, os.path.join(self.output_path, \"video_results.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04aec16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkDetector:\n",
    "    def __init__(self, model):\n",
    "        self.mp_holistic = model\n",
    "    \n",
    "    def detect_landmarks(self, frame):\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_rgb.flags.writeable = False\n",
    "        results = self.mp_holistic.process(frame_rgb)\n",
    "        frame_rgb.flags.writeable = True\n",
    "        frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "        return frame_bgr, results\n",
    "    \n",
    "    \n",
    "    def landmark_extraction(results):\n",
    "        pose = np.array([[coordinate.x, coordinate.y, coordinate.z, coordinate.visibility] for coordinate in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 4)\n",
    "        left_hand = np.array([[coordinate.x, coordinate.y, coordinate.z] for coordinate in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "        right_hand = np.array([[coordinate.x, coordinate.y, coordinate.z] for coordinate in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "        face = np.array([[coordinate.x, coordinate.y, coordinate.z] for coordinate in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468 * 3)\n",
    "        return np.concatenate([pose, left_hand, right_hand, face])\n",
    "   \n",
    "\n",
    "    class VideoProcessor:\n",
    "    def __init__(self, video_path):\n",
    "        self.video_path = video_path\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        self.mp_holistic = mp.solutions.holistic.Holistic()\n",
    "        self.detector = LandmarkDetector(self.mp_holistic)\n",
    "        \n",
    "        if not self.cap.isOpened():\n",
    "            print(\"Failed to open the video file.\")\n",
    "\n",
    "    def process_video(self):\n",
    "        while self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            processed_frame, results = self.detector.detect_landmarks(frame)\n",
    "            landmarks = LandmarkDetector.landmark_extraction(results)\n",
    "            cv2.imshow('Processed Frame', processed_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "video_path = 'C:\\\\Users\\\\saran\\\\OneDrive\\\\Desktop\\\\video_dummy_data\\\\00384.mp4'\n",
    "video_processor = VideoProcessor(video_path)\n",
    "video_processor.process_video()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ce5db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParquetWriter:\n",
    "    def __init__(self, landmarks_path, id_dict):\n",
    "        self.landmarks_path = landmarks_path\n",
    "        self.id_dict = id_dict\n",
    "\n",
    "    def write(self, np_array, video_id):\n",
    "        np_array_flat = np_array.flatten()\n",
    "        pa_array = pa.array(np_array_flat)\n",
    "        table = pa.Table.from_arrays([pa_array], names=[self.id_dict[video_id]])\n",
    "        writer = pq.ParquetWriter(self.landmarks_path + video_id + '.parquet', table.schema)\n",
    "        writer.write_table(table)\n",
    "        writer.close()\n",
    "        return\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e483a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor:\n",
    "    def __init__(self, videos_path, landmarks_path):\n",
    "        self.videos_path = videos_path\n",
    "        self.landmarks_path = landmarks_path\n",
    "        self.mp_holistic = mp.solutions.holistic\n",
    "\n",
    "    def process_videos(self):\n",
    "        for item in os.listdir(self.videos_path):\n",
    "            if item.endswith('.mp4'):  \n",
    "                cap = cv2.VideoCapture(os.path.join(self.videos_path, item))\n",
    "\n",
    "                # List that will receive the landmark's coordinates for each video\n",
    "                landmarks_list = []\n",
    "\n",
    "                # Set mediapipe model\n",
    "                with self.mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                    # Looping through all the frames\n",
    "                    while cap.isOpened():  \n",
    "                        # Reading the frames\n",
    "                        ret, frame = cap.read()\n",
    "                        if not ret: \n",
    "                            break\n",
    "                        # Making detections\n",
    "                        image, results = self.landmark_detection(frame, holistic)\n",
    "                        landmarks_list.append(self.landmark_extraction(results))\n",
    "\n",
    "                        cv2.waitKey(10)\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "\n",
    "                # Saving the NumPy array\n",
    "                np.save(os.path.join(self.landmarks_path, item.split(\".mp4\")[0]), np.array(landmarks_list))\n",
    "\n",
    "                # Converting and storing the array into parquet file\n",
    "                self.parquet_writer(np.array(landmarks_list), item.split('.mp4')[0])\n",
    "\n",
    "    def landmark_detection(self, frame, model):\n",
    "        # Color conversion \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # color conversion BGR to RGB.\n",
    "        frame.flags.writeable = False  \n",
    "        results = model.process(frame)  \n",
    "        frame.flags.writeable = True  \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # color conversion RGB to BGR.\n",
    "        return frame, results\n",
    "\n",
    "    def landmark_extraction(self, results):\n",
    "        pose = np.array([[coordinate.x, coordinate.y, coordinate.z, coordinate.visibility] for coordinate in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 4)\n",
    "        left_hand = np.array([[coordinate.x, coordinate.y, coordinate.z] for coordinate in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "        right_hand = np.array([[coordinate.x, coordinate.y, coordinate.z] for coordinate in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "        face = np.array([[coordinate.x, coordinate.y, coordinate.z] for coordinate in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468 * 3)\n",
    "        return np.concatenate([pose, left_hand, right_hand, face])\n",
    "    def parquet_writer(self, np_array, video_id):\n",
    "        np_array_flat = np_array.flatten()\n",
    "        pa_array = pa.array(np_array_flat)  # converting the numpy array into a pyarrow array\n",
    "        table = pa.Table.from_arrays([pa_array], names=[video_id])  # creating a table\n",
    "        writer = pq.ParquetWriter(os.path.join(self.landmarks_path, video_id + '.parquet'),\n",
    "                                  table.schema)  # Create a Parquet file writer\n",
    "        writer.write_table(table)  # Write the table to the Parquet file\n",
    "        writer.close()  # Close the Parquet file writer\n",
    "\n",
    "# Usage example:\n",
    "videos_path = \"C:\\\\Users\\\\saran\\\\OneDrive\\\\Desktop\\\\video_dummy_data\\\\\"\n",
    "landmarks_path = \"C:\\\\Users\\\\saran\\\\OneDrive\\\\Desktop\\\\extracted_landmarks_dummy\\\\\"\n",
    "\n",
    "video_processor = VideoProcessor(videos_path, landmarks_path)\n",
    "video_processor.process_videos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029da1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
