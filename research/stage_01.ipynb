{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import os\n",
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe.python.solutions.holistic' has no attribute 'FACEMESH_COUNTOURS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(image, cv2\u001b[39m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[1;32m     54\u001b[0m \u001b[39m# Draw face landmarks\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(image, results\u001b[39m.\u001b[39mface_landmarks, mp_holistic\u001b[39m.\u001b[39;49mFACEMESH_COUNTOURS,\n\u001b[1;32m     56\u001b[0m                           mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m, \u001b[39m110\u001b[39m, \u001b[39m10\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m     57\u001b[0m                           mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m, \u001b[39m256\u001b[39m, \u001b[39m121\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     58\u001b[0m                           )\n\u001b[1;32m     60\u001b[0m \u001b[39m# Draw right hand landmarks\u001b[39;00m\n\u001b[1;32m     61\u001b[0m mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(image, results\u001b[39m.\u001b[39mright_hand_landmarks, mp_holistic\u001b[39m.\u001b[39mHAND_CONNECTIONS,\n\u001b[1;32m     62\u001b[0m                           mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m, \u001b[39m22\u001b[39m, \u001b[39m10\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m),\n\u001b[1;32m     63\u001b[0m                           mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m, \u001b[39m44\u001b[39m, \u001b[39m121\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     64\u001b[0m                           )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mediapipe.python.solutions.holistic' has no attribute 'FACEMESH_COUNTOURS'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# model_path = 'model.h5'\n",
    "# model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize an empty array to store the landmarks\n",
    "landmarks = []\n",
    "\n",
    "# Constants for data preprocessing\n",
    "face_keep_points = [0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 61, 185, 40, 39, 37]\n",
    "left_hand_keep_points = [i for i in range(21)]\n",
    "pose_keep_points = [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "right_hand_keep_points = [i for i in range(21)]\n",
    "\n",
    "face_keep_idx = [face_keep_points[i] for i in range(len(face_keep_points))]\n",
    "left_hand_keep_idx = [i + 468 for i in left_hand_keep_points]\n",
    "pose_keep_idx = [i + 468 + 21 for i in pose_keep_points]\n",
    "right_hand_keep_idx = [i + 468 + 21 + 33 for i in right_hand_keep_points]\n",
    "\n",
    "landmarks_to_keep = face_keep_idx + left_hand_keep_idx + pose_keep_idx + right_hand_keep_idx\n",
    "TOTAL_ROWS = 543\n",
    "NUM_FRAMES = 30\n",
    "desired_num_rows = len(landmarks_to_keep) * 2\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Recolor Feed\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_COUNTOURS,\n",
    "                                  mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "                                  )\n",
    "\n",
    "        # Draw right hand landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        # Draw left hand landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        # Draw pose landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        try:\n",
    "            \n",
    "       \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark if results.face_landmarks else []\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "            # Extract Right Hand landmarks\n",
    "            right_hand = results.right_hand_landmarks.landmark if results.right_hand_landmarks else []\n",
    "            right_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in right_hand]).flatten())\n",
    "\n",
    "            # Extract Left Hand landmarks\n",
    "            left_hand = results.left_hand_landmarks.landmark if results.left_hand_landmarks else []\n",
    "            left_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in left_hand]).flatten())\n",
    "            \n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark if results.pose_landmarks else []\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "            # Check if the arrays are empty and handle the case\n",
    "            if len(face_row) == 0:\n",
    "                face_row = [0.0] * (len(face_keep_idx) )  # Filling with zeros if no face landmarks\n",
    "            else:\n",
    "                face_row = np.array(face_row)[face_keep_idx]\n",
    "\n",
    "            if len(right_hand_row) == 0:\n",
    "                right_hand_row = [0.0] * (len(right_hand_keep_idx))  # Filling with zeros if no right hand landmarks\n",
    "            else:\n",
    "                right_hand_row = np.array(right_hand_row)[right_hand_keep_idx]\n",
    "                \n",
    "            if len(pose_row) == 0:\n",
    "                pose_row = [0.0] * (len(pose_keep_idx) )  # Filling with zeros if no pose landmarks\n",
    "            else:\n",
    "                pose_row = np.array(pose_row)[pose_keep_idx]\n",
    "\n",
    "            if len(left_hand_row) == 0:\n",
    "                left_hand_row = [0.0] * (len(left_hand_keep_idx))  # Filling with zeros if no left hand landmarks\n",
    "            else:\n",
    "                left_hand_row = np.array(left_hand_row)[left_hand_keep_idx]\n",
    "\n",
    "            # Concatenate the specific landmark points\n",
    "            row = np.concatenate([\n",
    "                face_row,\n",
    "                right_hand_row,\n",
    "                pose_row,\n",
    "                left_hand_row\n",
    "            ])\n",
    "\n",
    "            # Reshape and create a DataFrame\n",
    "            data = pd.DataFrame([row])\n",
    "\n",
    "            # Adjust the number of frames\n",
    "            if data.shape[0] > NUM_FRAMES:  # if row = 1 > 30\n",
    "                indices = np.arange(0, data.shape[0], data.shape[0] // NUM_FRAMES)[:NUM_FRAMES]\n",
    "                data = data.iloc[indices]\n",
    "            elif data.shape[0] < NUM_FRAMES:  # padding the videos\n",
    "                rows = NUM_FRAMES - data.shape[0]\n",
    "                data = pd.concat([pd.DataFrame(np.zeros((rows, len(row)))), data])\n",
    "\n",
    "            print(data.shape)\n",
    "\n",
    "            # Continue with the rest of the processing as needed\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            pass\n",
    "\n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n",
    "    train_dir: Path\n",
    "    test_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ASLD_step2.constants import *\n",
    "from ASLD_step2.utils import read_yaml, create_directories\n",
    "\n",
    "\n",
    "CONFIG_FILE_PATH = Path(\"configs/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ASLD_step2.constants import *\n",
    "from ASLD_step2.utils import read_yaml,create_directories\n",
    "from ASLD_step2.entity import DataIngestionConfig\n",
    "from ASLD_step2.Exception import ASLDException\n",
    "import sys\n",
    "import shutil\n",
    "class Configuration:\n",
    "    def __init__(self,\n",
    "                config_filepath = CONFIG_FILE_PATH\n",
    "                ):\n",
    "        #reading the config.yaml file by importing from constants\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        #creating parent directories entity\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    this function is written to create the skeletion of DataIngestion entity \n",
    "    and will return path for DataIngestionConfig\n",
    "    \"\"\"  \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        #read config file to get data_ingestion attributes of DataIngestion\n",
    "        try:\n",
    "            config = self.config.data_ingestion\n",
    "            #create directories for attributes of data_ingestion\n",
    "            create_directories([config.root_dir])\n",
    "            create_directories([config.train_dir])\n",
    "            create_directories([config.test_dir])\n",
    "            \n",
    "            #assign the entity with its properities and return it\n",
    "            data_ingestion_config = DataIngestionConfig(\n",
    "                root_dir = config.root_dir,\n",
    "                source_URL = config.source_URL,\n",
    "                local_data_file = config.local_data_file,\n",
    "                unzip_dir = config.unzip_dir,\n",
    "                train_dir = config.train_dir,\n",
    "                test_dir = config.test_dir\n",
    "            )\n",
    "\n",
    "            return data_ingestion_config  \n",
    "        except Exception as e:\n",
    "            raise ASLDException(e,sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "def split_videos(self):\n",
    "        # Load the CSV file\n",
    "        csv_file = os.path.join(self.config.unzip_dir,'videos_id.csv')\n",
    "        df = pd.read_csv(csv_file)\n",
    "        captions = df['caption'].tolist()  # Get the captions column\n",
    "        ids = df['ID'].tolist()  # Get the IDs column\n",
    "\n",
    "        # Create a dictionary mapping IDs to captions\n",
    "        id_to_caption = dict(zip(ids, captions))\n",
    "\n",
    "        # List all video files in the video folder\n",
    "        video_files = [f for f in os.listdir(self.config.unzip_dir) if f.endswith(\".mp4\")]\n",
    "\n",
    "        # Split the videos\n",
    "        train_ratio = 0.80\n",
    "        videos_train, videos_test = train_test_split(video_files, train_size=train_ratio, random_state=42)\n",
    "\n",
    "        # Create train and test folders if they don't exist\n",
    "        train_folder = self.config.train_dir\n",
    "        test_folder =  self.config.test_dir\n",
    "        os.makedirs(train_folder, exist_ok=True)\n",
    "        os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "        # Move videos to train folder and label them\n",
    "        for video in videos_train:\n",
    "            video_id = os.path.splitext(video)[0]\n",
    "            caption = id_to_caption.get(video_id, \"Unknown\")  # Get the caption for the video ID\n",
    "            labeled_video = f\"{caption}_{video}\"\n",
    "            shutil.move(os.path.join(video_folder, video), os.path.join(train_folder, labeled_video))\n",
    "\n",
    "        # Move videos to test folder and label them\n",
    "        for video in videos_test:\n",
    "            video_id = os.path.splitext(video)[0]\n",
    "            caption = id_to_caption.get(video_id, \"Unknown\")  # Get the caption for the video ID\n",
    "            labeled_video = f\"{caption}_{video}\"\n",
    "            shutil.move(os.path.join(video_folder, video), os.path.join(test_folder, labeled_video))\n",
    "\n",
    "        print(\"Videos split into train and test sets.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
