{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This script preprocess the landmarks in the Action Recognition Approach for ASLD.\n",
    "\n",
    "Created by:\n",
    "- Marcus Vinicius da Silva Fernandes.\n",
    "\n",
    "2023-07-15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the landmarks\n",
    "Set up the paths of folders to locate the landmarks and the list (csv file) that associates the name of the video to the corresponding word in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up of the extracted landmarks save path\n",
    "landmarks_path = 'C:/Users/marcu/OneDrive/Documentos/Loyalist_College/AISC2006/train_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and shaping the landmarks to the desired number of frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desired number of frames\n",
    "- Each video will be reshaped to have the number of rows (or frames) equal to the desired number of frames defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading all the landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def load_landmarks(path):\n",
    "    videos = []\n",
    "    i = 0\n",
    "\n",
    "    for item in os.listdir(path):\n",
    "        if item.endswith('.npy'):  # working with npy files only\n",
    "            data = np.load(os.path.join(path, item))  # loading the numpy array into memory\n",
    "            if data.shape[0] > NUM_FRAMES:  # time-based sampling\n",
    "                indices = np.arange(0, data.shape[0], data.shape[0] // NUM_FRAMES)[:NUM_FRAMES]\n",
    "                data = data[indices]\n",
    "                videos.append(data)\n",
    "            elif data.shape[0] < NUM_FRAMES:  # padding the videos\n",
    "                data = np.pad(data, ((0, NUM_FRAMES - data.shape[0]), (0, 0)), mode='constant')\n",
    "                videos.append(data)\n",
    "            else:  # no change\n",
    "                videos.append(data)\n",
    "        i += 1\n",
    "        if i == 1000:\n",
    "            break\n",
    "\n",
    "    return np.array(videos)\n",
    "\n",
    "landmarks = load_landmarks(landmarks_path)\n",
    "landmarks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the file dataset_analysis.csv to load the association of landmark ids to words and its number of frames\n",
    "id_dict = {}  # initializing the dictionary that will receive the data\n",
    "num_frames = []  # initializing the list that will contain the number of frames of each landmark\n",
    "\n",
    "with open(landmarks_path + \"Updated Dataset.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)  # reading the data\n",
    "    next(csv_reader)  # to skip the header\n",
    "    for row in csv_reader:\n",
    "        if int(row[0]) <= 10000:\n",
    "            id_dict['0' * (5 - len(row[0])) + row[0]] = row[1]  # storing the content into a dictionary\n",
    "        else:\n",
    "            id_dict[row[0]] = row[1]  # storing the content into a dictionary\n",
    "        num_frames.append(int(row[7]))\n",
    "\n",
    "\n",
    "def load_landmarks(path):\n",
    "    videos, labels = [], []\n",
    "    i = 0\n",
    "\n",
    "    for item in os.listdir(path):\n",
    "        if item.endswith('.npy') and item.split('.npy')[0] in id_dict:  # working with npy files only\n",
    "            if i == 1000:\n",
    "                return np.array(videos), labels\n",
    "            data = np.load(os.path.join(path, item))  # loading the numpy array into memory\n",
    "            if data.shape[0] > NUM_FRAMES:  # time-based sampling\n",
    "                indices = np.arange(0, data.shape[0], data.shape[0] // NUM_FRAMES)[:NUM_FRAMES]\n",
    "                data = data[indices]\n",
    "                videos.append(data)\n",
    "            elif data.shape[0] < NUM_FRAMES:  # padding the videos\n",
    "                data = np.pad(data, ((0, NUM_FRAMES - data.shape[0]), (0, 0)), mode='constant')\n",
    "                videos.append(data)\n",
    "            else:  # no change\n",
    "                videos.append(data)\n",
    "            labels.append(id_dict[item.split('.npy')[0]])\n",
    "            i += 1\n",
    "\n",
    "    return np.array(videos), np.array(labels)\n",
    "\n",
    "landmarks, train_labels = load_landmarks(landmarks_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping landmarks\n",
    "\n",
    "Each column is composed of coordinates in the folllwing order of models:\n",
    "- Pose: 2 coordinates x 33 landmarks = 66 values.\n",
    "- Left hand: 2 coordinates x 21 landmarks = 42 values.\n",
    "- Right hand: 2 coordinates x 21 landmarks = 42 values.\n",
    "- Face: 2 coordinates x 468 landmarks = 936 values.\n",
    "\n",
    "Each row (each frame) have a total of 1086 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose Model\n",
    "\n",
    "Dropping the points 9, 10, 17, 18, 19, 20, 21, 22, 25, 25, 27, 28, 29, 30, 31, and 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points to drop\n",
    "pose_drop_points = [9, 10, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "\n",
    "# Indexes of the points to drop\n",
    "pose_drop_index = []\n",
    "for i in pose_drop_points:\n",
    "    # pose_drop_index.append([(i - 1) * 2, (i - 1) * 2 + 1, (i - 1) * 4 + 2, (i - 1) * 4 + 3])\n",
    "    pose_drop_index.append([(i - 1) * 2, (i - 1) * 2 + 1])\n",
    "\n",
    "pose_drop_index = np.array(pose_drop_index).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 60, 1054)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the columns\n",
    "landmarks = np.delete(landmarks, pose_drop_index, 2)\n",
    "landmarks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current composition of the columns\n",
    "\n",
    "Each column is composed of coordinates in the folllwing order of models:\n",
    "- Pose: 2 coordinates x 17 landmarks = 34 values.\n",
    "- Left hand: 2 coordinates x 21 landmarks = 42 values.\n",
    "- Right hand: 2 coordinates x 21 landmarks = 42 values.\n",
    "- Face: 2 coordinates x 468 landmarks = 936 values.\n",
    "\n",
    "Each row (each frame) will have a total of 1054 values after concatenation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left and Right Hands Models\n",
    "\n",
    "These models will be kept as they are. No columns will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Model\n",
    "\n",
    "Only the landmark coordinates corresponding to the outline of the lips will be kept? 0, 267, 269, 270, 409, 291, 375, 321, 403, 314, 17, 84, 181, 91, 146, 61, 185, 40, 39, and 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points to keep\n",
    "face_keep_points = [0, 267, 269, 270, 409, 291, 375, 321, 403, 314, 17, 84, 181, 91, 146, 61, 185, 40, 39, 27]\n",
    "face_keep_points.sort()\n",
    "\n",
    "# Points to drop\n",
    "face_drop_points = np.delete([i for i in range(468)], face_keep_points, 0)\n",
    "\n",
    "# Indexes of the points to drop\n",
    "face_drop_index = []\n",
    "for i in face_drop_points:\n",
    "    face_drop_index.append([(i - 1) * 2 + 120, (i - 1) * 2 + 120 + 1])\n",
    "\n",
    "face_drop_index = np.array(face_drop_index).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 60, 158)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the columns\n",
    "landmarks = np.delete(landmarks, face_drop_index, 2)\n",
    "landmarks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final composition of the columns\n",
    "\n",
    "Each column is composed of coordinates in the folllwing order of models:\n",
    "- Pose: 2 coordinates x 17 landmarks = 34 values.\n",
    "- Left hand: 2 coordinates x 21 landmarks = 42 values.\n",
    "- Right hand: 2 coordinates x 21 landmarks = 42 values.\n",
    "- Face: 2 coordinates x 20 landmarks = 40 values.\n",
    "\n",
    "Each row (each frame) will have a total of 158 values after concatenation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(landmarks, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_val = label_binarizer.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    return (array - np.min(array)) / (np.max(array) - np.min(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train)\n",
    "x_val = normalize(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optimized model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Masking Layer\n",
    "model.add(Masking(mask_value=0, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(LSTM(64,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(units=1, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(32, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 269) and (32, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(x_val, y_val))\n",
      "File \u001b[1;32mc:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filepa0mixz8.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\marcu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 269) and (32, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=500, validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
